# GPT2

Training a GPT2 model

This project contains code for training a GPT2 model (124 million parameter) from scratch. It is based on the youtube lessons from Andrej Karapathy (https://www.youtube.com/watch?v=l8pRSuU81PU)

